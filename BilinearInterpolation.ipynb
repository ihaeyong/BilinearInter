{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's a simple implementation of bilinear interpolation on tensors using PyTorch.\n",
    "\n",
    "I wrote this up since I ended up learning a lot about options for interpolation in both the numpy and PyTorch ecosystems. More generally than just interpolation, too, it's also a nice case study in how PyTorch magically can put very numpy-like code on the GPU (and by the way, do autodiff for you too).\n",
    "\n",
    "For interpolation in PyTorch, this open issue calls for more interpolation features. There is now a nn.functional.grid_sample() feature but at least at first this didn't look like what I needed (but we'll come back to this later).\n",
    "\n",
    "In particular I wanted to take an image, W x H x C, and sample it many times at different random locations. Note also that this is different than upsampling which exhaustively samples and also doesn't give us flexibility with the precision of sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bilinear_interpolate_numpy(im, x, y):\n",
    "    x0 = np.floor(x).astype(int)\n",
    "    x1 = x0 + 1\n",
    "    y0 = np.floor(y).astype(int)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    x0 = np.clip(x0, 0, im.shape[1]-1)\n",
    "    x1 = np.clip(x1, 0, im.shape[1]-1)\n",
    "    y0 = np.clip(y0, 0, im.shape[0]-1)\n",
    "    y1 = np.clip(y1, 0, im.shape[0]-1)\n",
    "\n",
    "    Ia = im[ y0, x0 ]\n",
    "    Ib = im[ y1, x0 ]\n",
    "    Ic = im[ y0, x1 ]\n",
    "    Id = im[ y1, x1 ]\n",
    "\n",
    "    wa = (x1-x) * (y1-y)\n",
    "    wb = (x1-x) * (y-y0)\n",
    "    wc = (x-x0) * (y1-y)\n",
    "    wd = (x-x0) * (y-y0)\n",
    "\n",
    "    return (Ia.T*wa).T + (Ib.T*wb).T + (Ic.T*wc).T + (Id.T*wd).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dtype = torch.cuda.FloatTensor\n",
    "dtype_long = torch.cuda.LongTensor\n",
    "\n",
    "def bilinear_interpolate_torch(im, x, y):\n",
    "    x0 = torch.floor(x).type(dtype_long)\n",
    "    x1 = x0 + 1\n",
    "    \n",
    "    y0 = torch.floor(y).type(dtype_long)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    x0 = torch.clamp(x0, 0, im.shape[1]-1)\n",
    "    x1 = torch.clamp(x1, 0, im.shape[1]-1)\n",
    "    y0 = torch.clamp(y0, 0, im.shape[0]-1)\n",
    "    y1 = torch.clamp(y1, 0, im.shape[0]-1)\n",
    "    \n",
    "    Ia = im[ y0, x0 ][0]\n",
    "    Ib = im[ y1, x0 ][0]\n",
    "    Ic = im[ y0, x1 ][0]\n",
    "    Id = im[ y1, x1 ][0]\n",
    "    \n",
    "    wa = (x1.type(dtype)-x) * (y1.type(dtype)-y)\n",
    "    wb = (x1.type(dtype)-x) * (y-y0.type(dtype))\n",
    "    wc = (x-x0.type(dtype)) * (y1.type(dtype)-y)\n",
    "    wd = (x-x0.type(dtype)) * (y-y0.type(dtype))\n",
    "\n",
    "    return torch.t((torch.t(Ia)*wa)) + torch.t(torch.t(Ib)*wb) + torch.t(torch.t(Ic)*wc) + torch.t(torch.t(Id)*wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for correctness\n",
    "Bilinear interpolation is very simple but there are a few things that can be easily messed up.\n",
    "\n",
    "I did a quick comparison for correctness with SciPy's interp2d.\n",
    "\n",
    "Side note: there are actually a ton of interpolation options in SciPy but none I tested met my critera of (a) doing bilinear interpolation for high-dimensional spaces and (b) efficiently use gridded data. The ones I tested that were built for many dimensions were requiring me to specify sample points for all of those dimensions (and doing trilinear, or other) interpolation. I could get LinearNDInterpolator to do bilinear interpolation for high dimensional vectors but this does not meet criteria (b). There's probably a better option but, at any rate, I gave up and went back to my numpy and PyTorch options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy result: [2.68]\n",
      "scipy result: [2.68]\n",
      "torch result:\n",
      " 2.6800\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Also use scipy to check for correctness\n",
    "import scipy.interpolate\n",
    "def bilinear_interpolate_scipy(image, x, y):\n",
    "    x_indices = np.arange(image.shape[0])\n",
    "    y_indices = np.arange(image.shape[1])\n",
    "    interp_func = scipy.interpolate.interp2d(x_indices, y_indices, image, kind='linear')\n",
    "    return interp_func(x,y)\n",
    "\n",
    "# Make small sample data that's easy to interpret\n",
    "image = np.ones((5,5))\n",
    "image[3,3] = 4\n",
    "image[3,4] = 3\n",
    "\n",
    "sample_x, sample_y = np.asarray([3.2]), np.asarray([3.4])\n",
    "\n",
    "print (\"numpy result:\", bilinear_interpolate_numpy(image, sample_x, sample_y))\n",
    "print (\"scipy result:\", bilinear_interpolate_scipy(image, sample_x, sample_y))\n",
    "\n",
    "image = torch.unsqueeze(torch.FloatTensor(image).type(dtype),2)\n",
    "sample_x = torch.FloatTensor([sample_x]).type(dtype)\n",
    "sample_y = torch.FloatTensor([sample_y]).type(dtype)\n",
    "\n",
    "print(\"torch result:{}\".format(bilinear_interpolate_torch(image, sample_x, sample_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High dimensional bilinear interpolation\n",
    "For the correctness test comparing with scipy, we couldn't do W x H x C interpolation for anything but C=1. Now though, we can do bilinear interpolation in either numpy or torch for arbitrary C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03487975  0.05992728 -0.32450413  1.73506905 -0.12563051  0.17523377\n",
      "   0.66694222]\n",
      " [ 0.06435581  0.9336627  -0.31199044  0.33880198 -0.20322331 -0.31408149\n",
      "   1.20000908]\n",
      " [ 0.21110027 -1.04296268 -0.58333472 -0.44477671 -0.39599681  0.98248355\n",
      "  -0.41903184]\n",
      " [-0.23086448  0.44345576 -1.59667113  0.90401681  0.06551464 -0.75609012\n",
      "   0.28220755]]\n",
      "\n",
      "-0.0349  0.0599 -0.3245  1.7351 -0.1256  0.1752  0.6669\n",
      " 0.0644  0.9337 -0.3120  0.3388 -0.2032 -0.3141  1.2000\n",
      " 0.2111 -1.0430 -0.5833 -0.4448 -0.3960  0.9825 -0.4190\n",
      "-0.2309  0.4435 -1.5967  0.9040  0.0655 -0.7561  0.2822\n",
      "[torch.cuda.FloatTensor of size 4x7 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do high dimensional bilinear interpolation in numpy and PyTorch\n",
    "W, H, C = 25, 25, 7\n",
    "image = np.random.randn(W, H, C)\n",
    "\n",
    "num_samples = 4\n",
    "samples_x, samples_y = np.random.rand(num_samples)*(W-1), np.random.rand(num_samples)*(H-1)\n",
    "\n",
    "print (bilinear_interpolate_numpy(image, samples_x, samples_y))\n",
    "\n",
    "image = torch.from_numpy(image).type(dtype)\n",
    "samples_x = torch.FloatTensor([samples_x]).type(dtype)\n",
    "samples_y = torch.FloatTensor([samples_y]).type(dtype)\n",
    "\n",
    "print(bilinear_interpolate_torch(image, samples_x, samples_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bechmarking: numpy (CPU) vs. pytorch (CPU) vs. pytorch (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy took        0.01631951332092285\n",
      "torch on CPU took 0.20528769493103027\n",
      "torch on GPU took 0.04155755043029785\n"
     ]
    }
   ],
   "source": [
    "# Timing comparison for WxHxC (where C is large for a high dimensional descriptor)\n",
    "W, H, C = 640, 480, 32\n",
    "image = np.random.randn(W, H, C)\n",
    "\n",
    "num_samples = 10000\n",
    "samples_x, samples_y = np.random.rand(num_samples)*(W-1), np.random.rand(num_samples)*(H-1)\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "bilinear_interpolate_numpy(image, samples_x, samples_y)\n",
    "print (\"numpy took       \", time.time() - start)\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "dtype_long = torch.LongTensor\n",
    "image = torch.FloatTensor(image).type(dtype)\n",
    "samples_x = torch.FloatTensor([samples_x]).type(dtype)\n",
    "samples_y = torch.FloatTensor([samples_y]).type(dtype)\n",
    "\n",
    "start = time.time()\n",
    "bilinear_interpolate_torch(image, samples_x, samples_y)\n",
    "print (\"torch on CPU took\", time.time() - start) \n",
    "\n",
    "dtype = torch.cuda.FloatTensor\n",
    "dtype_long = torch.cuda.LongTensor\n",
    "image = image.type(dtype)\n",
    "samples_x = samples_x.type(dtype)\n",
    "samples_y = samples_y.type(dtype)\n",
    "\n",
    "start = time.time()\n",
    "bilinear_interpolate_torch(image, samples_x, samples_y)\n",
    "print (\"torch on GPU took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the available nn.functional.grid_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  2.6800\n",
      "[torch.cuda.FloatTensor of size 1x1x1x1 (GPU 0)]\n",
      "\n",
      "torch gridsample took  0.0016460418701171875\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional\n",
    "dtype = torch.cuda.FloatTensor\n",
    "dtype_long = torch.cuda.LongTensor\n",
    "\n",
    "def bilinear_interpolate_torch_gridsample(image, samples_x, samples_y):\n",
    "                                                # input image is: W x H x C\n",
    "    image = image.permute(2,0,1)                # change to:      C x W x H\n",
    "    image = image.unsqueeze(0)                  # change to:  1 x C x W x H\n",
    "    samples_x = samples_x.unsqueeze(2)\n",
    "    samples_x = samples_x.unsqueeze(3)\n",
    "    samples_y = samples_y.unsqueeze(2)\n",
    "    samples_y = samples_y.unsqueeze(3)\n",
    "    samples = torch.cat([samples_x, samples_y],3)\n",
    "    samples[:,:,:,0] = (samples[:,:,:,0]/(W-1)) # normalize to between  0 and 1\n",
    "    samples[:,:,:,1] = (samples[:,:,:,1]/(H-1)) # normalize to between  0 and 1\n",
    "    samples = samples*2-1                       # normalize to between -1 and 1\n",
    "    return torch.nn.functional.grid_sample(image, samples)\n",
    "\n",
    "# Correctness test\n",
    "W, H, C = 5, 5, 1\n",
    "test_image = torch.ones(W,H,C).type(dtype)\n",
    "test_image[3,3,:] = 4\n",
    "test_image[3,4,:] = 3\n",
    "\n",
    "test_samples_x = torch.FloatTensor([[3.2]]).type(dtype)\n",
    "test_samples_y = torch.FloatTensor([[3.4]]).type(dtype)\n",
    "\n",
    "print (bilinear_interpolate_torch_gridsample(test_image, test_samples_x, test_samples_y))\n",
    "\n",
    "# Benchmark\n",
    "start = time.time()\n",
    "bilinear_interpolate_torch_gridsample(image, samples_x, samples_y)\n",
    "print (\"torch gridsample took \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
