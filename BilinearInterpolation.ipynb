{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's a simple implementation of bilinear interpolation on tensors using PyTorch.\n",
    "\n",
    "I wrote this up since I ended up learning a lot about options for interpolation in both the numpy and PyTorch ecosystems. More generally than just interpolation, too, it's also a nice case study in how PyTorch magically can put very numpy-like code on the GPU (and by the way, do autodiff for you too).\n",
    "\n",
    "For interpolation in PyTorch, this open issue calls for more interpolation features. There is now a nn.functional.grid_sample() feature but at least at first this didn't look like what I needed (but we'll come back to this later).\n",
    "\n",
    "In particular I wanted to take an image, W x H x C, and sample it many times at different random locations. Note also that this is different than upsampling which exhaustively samples and also doesn't give us flexibility with the precision of sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bilinear_interpolate_numpy(im, x, y):\n",
    "    x0 = np.floor(x).astype(int)\n",
    "    x1 = x0 + 1\n",
    "    y0 = np.floor(y).astype(int)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    x0 = np.clip(x0, 0, im.shape[1]-1)\n",
    "    x1 = np.clip(x1, 0, im.shape[1]-1)\n",
    "    y0 = np.clip(y0, 0, im.shape[0]-1)\n",
    "    y1 = np.clip(y1, 0, im.shape[0]-1)\n",
    "\n",
    "    Ia = im[ y0, x0 ]\n",
    "    Ib = im[ y1, x0 ]\n",
    "    Ic = im[ y0, x1 ]\n",
    "    Id = im[ y1, x1 ]\n",
    "\n",
    "    wa = (x1-x) * (y1-y)\n",
    "    wb = (x1-x) * (y-y0)\n",
    "    wc = (x-x0) * (y1-y)\n",
    "    wd = (x-x0) * (y-y0)\n",
    "\n",
    "    return (Ia.T*wa).T + (Ib.T*wb).T + (Ic.T*wc).T + (Id.T*wd).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dtype = torch.cuda.FloatTensor\n",
    "dtype_long = torch.cuda.LongTensor\n",
    "\n",
    "def bilinear_interpolate_torch(im, x, y):\n",
    "    x0 = torch.floor(x).type(dtype_long)\n",
    "    x1 = x0 + 1\n",
    "    \n",
    "    y0 = torch.floor(y).type(dtype_long)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    x0 = torch.clamp(x0, 0, im.shape[1]-1)\n",
    "    x1 = torch.clamp(x1, 0, im.shape[1]-1)\n",
    "    y0 = torch.clamp(y0, 0, im.shape[0]-1)\n",
    "    y1 = torch.clamp(y1, 0, im.shape[0]-1)\n",
    "    \n",
    "    Ia = im[ y0, x0 ][0]\n",
    "    Ib = im[ y1, x0 ][0]\n",
    "    Ic = im[ y0, x1 ][0]\n",
    "    Id = im[ y1, x1 ][0]\n",
    "    \n",
    "    wa = (x1.type(dtype)-x) * (y1.type(dtype)-y)\n",
    "    wb = (x1.type(dtype)-x) * (y-y0.type(dtype))\n",
    "    wc = (x-x0.type(dtype)) * (y1.type(dtype)-y)\n",
    "    wd = (x-x0.type(dtype)) * (y-y0.type(dtype))\n",
    "\n",
    "    return torch.t((torch.t(Ia)*wa)) + torch.t(torch.t(Ib)*wb) + torch.t(torch.t(Ic)*wc) + torch.t(torch.t(Id)*wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for correctness\n",
    "Bilinear interpolation is very simple but there are a few things that can be easily messed up.\n",
    "\n",
    "I did a quick comparison for correctness with SciPy's interp2d.\n",
    "\n",
    "Side note: there are actually a ton of interpolation options in SciPy but none I tested met my critera of (a) doing bilinear interpolation for high-dimensional spaces and (b) efficiently use gridded data. The ones I tested that were built for many dimensions were requiring me to specify sample points for all of those dimensions (and doing trilinear, or other) interpolation. I could get LinearNDInterpolator to do bilinear interpolation for high dimensional vectors but this does not meet criteria (b). There's probably a better option but, at any rate, I gave up and went back to my numpy and PyTorch options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy result: [2.68]\n",
      "scipy result: [2.68]\n",
      "torch result:\n",
      " 2.6800\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Also use scipy to check for correctness\n",
    "import scipy.interpolate\n",
    "def bilinear_interpolate_scipy(image, x, y):\n",
    "    x_indices = np.arange(image.shape[0])\n",
    "    y_indices = np.arange(image.shape[1])\n",
    "    interp_func = scipy.interpolate.interp2d(x_indices, y_indices, image, kind='linear')\n",
    "    return interp_func(x,y)\n",
    "\n",
    "# Make small sample data that's easy to interpret\n",
    "image = np.ones((5,5))\n",
    "image[3,3] = 4\n",
    "image[3,4] = 3\n",
    "\n",
    "sample_x, sample_y = np.asarray([3.2]), np.asarray([3.4])\n",
    "\n",
    "print (\"numpy result:\", bilinear_interpolate_numpy(image, sample_x, sample_y))\n",
    "print (\"scipy result:\", bilinear_interpolate_scipy(image, sample_x, sample_y))\n",
    "\n",
    "image = torch.unsqueeze(torch.FloatTensor(image).type(dtype),2)\n",
    "sample_x = torch.FloatTensor([sample_x]).type(dtype)\n",
    "sample_y = torch.FloatTensor([sample_y]).type(dtype)\n",
    "\n",
    "print(\"torch result:{}\".format(bilinear_interpolate_torch(image, sample_x, sample_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High dimensional bilinear interpolation\n",
    "For the correctness test comparing with scipy, we couldn't do W x H x C interpolation for anything but C=1. Now though, we can do bilinear interpolation in either numpy or torch for arbitrary C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03487975  0.05992728 -0.32450413  1.73506905 -0.12563051  0.17523377\n",
      "   0.66694222]\n",
      " [ 0.06435581  0.9336627  -0.31199044  0.33880198 -0.20322331 -0.31408149\n",
      "   1.20000908]\n",
      " [ 0.21110027 -1.04296268 -0.58333472 -0.44477671 -0.39599681  0.98248355\n",
      "  -0.41903184]\n",
      " [-0.23086448  0.44345576 -1.59667113  0.90401681  0.06551464 -0.75609012\n",
      "   0.28220755]]\n",
      "\n",
      "-0.0349  0.0599 -0.3245  1.7351 -0.1256  0.1752  0.6669\n",
      " 0.0644  0.9337 -0.3120  0.3388 -0.2032 -0.3141  1.2000\n",
      " 0.2111 -1.0430 -0.5833 -0.4448 -0.3960  0.9825 -0.4190\n",
      "-0.2309  0.4435 -1.5967  0.9040  0.0655 -0.7561  0.2822\n",
      "[torch.cuda.FloatTensor of size 4x7 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do high dimensional bilinear interpolation in numpy and PyTorch\n",
    "W, H, C = 25, 25, 7\n",
    "image = np.random.randn(W, H, C)\n",
    "\n",
    "num_samples = 4\n",
    "samples_x, samples_y = np.random.rand(num_samples)*(W-1), np.random.rand(num_samples)*(H-1)\n",
    "\n",
    "print (bilinear_interpolate_numpy(image, samples_x, samples_y))\n",
    "\n",
    "image = torch.from_numpy(image).type(dtype)\n",
    "samples_x = torch.FloatTensor([samples_x]).type(dtype)\n",
    "samples_y = torch.FloatTensor([samples_y]).type(dtype)\n",
    "\n",
    "print(bilinear_interpolate_torch(image, samples_x, samples_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bechmarking: numpy (CPU) vs. pytorch (CPU) vs. pytorch (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy took        0.01631951332092285\n",
      "torch on CPU took 0.20528769493103027\n",
      "torch on GPU took 0.04155755043029785\n"
     ]
    }
   ],
   "source": [
    "# Timing comparison for WxHxC (where C is large for a high dimensional descriptor)\n",
    "W, H, C = 640, 480, 32\n",
    "image = np.random.randn(W, H, C)\n",
    "\n",
    "num_samples = 10000\n",
    "samples_x, samples_y = np.random.rand(num_samples)*(W-1), np.random.rand(num_samples)*(H-1)\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "bilinear_interpolate_numpy(image, samples_x, samples_y)\n",
    "print (\"numpy took       \", time.time() - start)\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "dtype_long = torch.LongTensor\n",
    "image = torch.FloatTensor(image).type(dtype)\n",
    "samples_x = torch.FloatTensor([samples_x]).type(dtype)\n",
    "samples_y = torch.FloatTensor([samples_y]).type(dtype)\n",
    "\n",
    "start = time.time()\n",
    "bilinear_interpolate_torch(image, samples_x, samples_y)\n",
    "print (\"torch on CPU took\", time.time() - start) \n",
    "\n",
    "dtype = torch.cuda.FloatTensor\n",
    "dtype_long = torch.cuda.LongTensor\n",
    "image = image.type(dtype)\n",
    "samples_x = samples_x.type(dtype)\n",
    "samples_y = samples_y.type(dtype)\n",
    "\n",
    "start = time.time()\n",
    "bilinear_interpolate_torch(image, samples_x, samples_y)\n",
    "print (\"torch on GPU took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the available nn.functional.grid_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  2.6800\n",
      "[torch.cuda.FloatTensor of size 1x1x1x1 (GPU 0)]\n",
      "\n",
      "torch gridsample took  0.0016460418701171875\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional\n",
    "dtype = torch.cuda.FloatTensor\n",
    "dtype_long = torch.cuda.LongTensor\n",
    "\n",
    "def bilinear_interpolate_torch_gridsample(image, samples_x, samples_y):\n",
    "                                                # input image is: W x H x C\n",
    "    image = image.permute(2,0,1)                # change to:      C x W x H\n",
    "    image = image.unsqueeze(0)                  # change to:  1 x C x W x H\n",
    "    samples_x = samples_x.unsqueeze(2)\n",
    "    samples_x = samples_x.unsqueeze(3)\n",
    "    samples_y = samples_y.unsqueeze(2)\n",
    "    samples_y = samples_y.unsqueeze(3)\n",
    "    samples = torch.cat([samples_x, samples_y],3)\n",
    "    samples[:,:,:,0] = (samples[:,:,:,0]/(W-1)) # normalize to between  0 and 1\n",
    "    samples[:,:,:,1] = (samples[:,:,:,1]/(H-1)) # normalize to between  0 and 1\n",
    "    samples = samples*2-1                       # normalize to between -1 and 1\n",
    "    return torch.nn.functional.grid_sample(image, samples)\n",
    "\n",
    "# Correctness test\n",
    "W, H, C = 5, 5, 1\n",
    "test_image = torch.ones(W,H,C).type(dtype)\n",
    "test_image[3,3,:] = 4\n",
    "test_image[3,4,:] = 3\n",
    "\n",
    "test_samples_x = torch.FloatTensor([[3.2]]).type(dtype)\n",
    "test_samples_y = torch.FloatTensor([[3.4]]).type(dtype)\n",
    "\n",
    "print (bilinear_interpolate_torch_gridsample(test_image, test_samples_x, test_samples_y))\n",
    "\n",
    "# Benchmark\n",
    "start = time.time()\n",
    "bilinear_interpolate_torch_gridsample(image, samples_x, samples_y)\n",
    "print (\"torch gridsample took \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High dimensional bilinear interpolation\n",
    "For the correctness test comparing with scipy, we couldn't do H x C interpolation for anything but C=1. Now though, we can do bilinear interpolation in either numpy or torch for arbitrary C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.80408495 -0.3605468  -0.49353077 ...  1.03704021 -0.72125335\n",
      "    0.769743  ]\n",
      "  [-0.37596455  0.38516289  1.8144742  ...  1.11418533  0.9892282\n",
      "   -0.82162355]\n",
      "  [ 1.06390295 -1.15098164  0.44397855 ... -0.34701702 -0.40195921\n",
      "   -0.50611539]\n",
      "  ...\n",
      "  [-2.16148843 -0.28735546 -0.65934313 ... -2.49980777 -0.6550439\n",
      "    0.31174935]\n",
      "  [-1.26001232 -0.29804738  1.00841776 ... -0.07920075 -0.67197759\n",
      "   -1.68075489]\n",
      "  [ 0.47754207 -1.29339343 -0.15063431 ... -0.41592414  1.81205171\n",
      "   -1.18107249]]\n",
      "\n",
      " [[ 0.66450915 -0.32658933  0.402464   ... -0.03107425 -0.99818075\n",
      "   -0.25391999]\n",
      "  [-0.87278078 -1.41842194  1.26444189 ... -0.78948578  0.70247765\n",
      "    1.77515542]\n",
      "  [-0.25086732  0.56394069  0.83971729 ... -0.68959276 -0.01290295\n",
      "   -0.44932601]\n",
      "  ...\n",
      "  [-0.70048765 -0.63672346 -2.2091686  ...  1.14704603 -1.1555942\n",
      "    0.86892644]\n",
      "  [-0.08803624 -0.55184275 -0.96963481 ...  1.1300187  -0.30606453\n",
      "   -0.44322507]\n",
      "  [ 0.95104782 -0.43349358 -0.03476632 ...  0.7565349   1.69916694\n",
      "   -0.80871566]]\n",
      "\n",
      " [[-0.66028256 -0.89850992 -0.51849574 ...  1.90812945 -1.55453245\n",
      "   -0.16072134]\n",
      "  [-0.17022871  1.12880785  0.10525834 ... -0.91806892  0.14725943\n",
      "   -2.10176288]\n",
      "  [-0.92250543  0.69437495 -0.38166332 ...  0.7461763   0.32210686\n",
      "   -0.69168687]\n",
      "  ...\n",
      "  [-1.70281561  1.76824474 -0.87984787 ... -2.33499794  0.71450192\n",
      "    0.61711912]\n",
      "  [-0.19907235  0.31580853  1.34755779 ... -0.21868673 -0.01404466\n",
      "   -0.46086727]\n",
      "  [ 1.03147693  0.95068525 -1.17697742 ...  0.10626887 -1.41194463\n",
      "   -0.14402106]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.81103679 -0.01609937 -1.03878291 ... -0.33398946 -0.61799736\n",
      "    2.0307803 ]\n",
      "  [ 1.04260242  0.65032767  2.08617673 ...  1.21399763 -0.66817073\n",
      "    1.31974627]\n",
      "  [-1.89955305 -0.12789019 -1.3782119  ... -0.02277458  0.54659628\n",
      "    1.23239718]\n",
      "  ...\n",
      "  [-0.39334351  0.05392032  0.79199405 ... -0.35524452  0.2460996\n",
      "   -0.24922571]\n",
      "  [-1.97467942 -1.73725412 -1.14274443 ...  1.9995503  -0.59392749\n",
      "    0.59477388]\n",
      "  [ 0.25837077  0.04247859  1.26200459 ... -0.20938446 -2.28583611\n",
      "    0.03348659]]\n",
      "\n",
      " [[-0.70419981 -0.11254191  1.02305994 ... -0.23041081 -0.81883949\n",
      "    0.1749981 ]\n",
      "  [ 0.52423807  0.42997242 -0.74205494 ... -0.0710293   0.04569581\n",
      "   -0.12819032]\n",
      "  [ 0.76538143 -1.15000245  2.08168303 ...  0.52089906 -0.95866708\n",
      "   -0.49418994]\n",
      "  ...\n",
      "  [-0.50242646  0.75076402 -0.88432048 ... -1.57486946 -0.7356549\n",
      "    0.41927492]\n",
      "  [-0.8710695  -0.96791415 -2.0640479  ... -0.26872987 -0.83298145\n",
      "   -1.89351848]\n",
      "  [ 0.81873041 -0.48972657  0.29500411 ...  0.73790253 -2.43414265\n",
      "    0.73126849]]\n",
      "\n",
      " [[ 0.73672374 -0.7305762  -0.04797956 ... -0.76883713  0.62302715\n",
      "   -0.4462284 ]\n",
      "  [ 0.79115751 -0.69544216  0.45776805 ... -2.37863486  1.63402242\n",
      "    0.85255942]\n",
      "  [-0.91615895  0.29926438  0.60068388 ... -0.44322794  1.00133798\n",
      "   -0.03433943]\n",
      "  ...\n",
      "  [-0.50771504  1.96031955  1.14631748 ... -0.11633275  0.51408529\n",
      "   -0.74585727]\n",
      "  [ 0.27436912 -1.22941334  0.09228817 ...  1.58108164 -0.89638494\n",
      "   -1.22206125]\n",
      "  [ 0.21591022  1.95975548  0.02066902 ... -0.02234628 -0.760163\n",
      "   -1.04788024]]]\n",
      "[ 3.3112384   3.77460931 18.50233888 18.40231383]\n",
      "[ 5.71275825 12.26009586  4.64831355  4.01237641]\n",
      "[[ 0.1366717  -0.76190231 -1.08655958 -0.56435837 -0.17524978  0.3898081\n",
      "  -0.70910615]\n",
      " [-1.08562124  0.58977504  0.28838297 -1.90042293 -0.23423128  0.62369755\n",
      "   0.51097157]\n",
      " [ 0.30767688 -0.39655059  0.38218377 -1.34621197 -0.80284345  0.38349747\n",
      "   0.41030407]\n",
      " [ 1.61201004  0.29489316 -0.84601521 -0.69150216  0.14727243  0.07972652\n",
      "   0.06966102]]\n",
      "\n",
      " 0.1367 -0.7619 -1.0866 -0.5644 -0.1752  0.3898 -0.7091\n",
      "-1.0856  0.5898  0.2884 -1.9004 -0.2342  0.6237  0.5110\n",
      " 0.3077 -0.3966  0.3822 -1.3462 -0.8028  0.3835  0.4103\n",
      " 1.6120  0.2949 -0.8460 -0.6915  0.1473  0.0797  0.0697\n",
      "[torch.cuda.FloatTensor of size 4x7 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do high dimensional bilinear interpolation in numpy and PyTorch\n",
    "W, H, C = 25, 25, 7\n",
    "image = np.random.randn(W, H, C)\n",
    "print(image)\n",
    "\n",
    "num_samples = 4\n",
    "samples_x, samples_y = np.random.rand(num_samples)*(W-1), np.random.rand(num_samples)*(H-1)\n",
    "print(samples_x)\n",
    "print(samples_y)\n",
    "\n",
    "print (bilinear_interpolate_numpy(image, samples_x, samples_y))\n",
    "\n",
    "image = torch.from_numpy(image).type(dtype)\n",
    "samples_x = torch.FloatTensor([samples_x]).type(dtype)\n",
    "samples_y = torch.FloatTensor([samples_y]).type(dtype)\n",
    "\n",
    "print(bilinear_interpolate_torch(image, samples_x, samples_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.6416\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 1D, 2D tensors at /pytorch/torch/lib/TH/generic/THTensorMath.c:1429",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3d6b76d843f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m# > tensor([-0.6748], grad_fn=<ThAddBackward>)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanual_bilinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_zeros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/motifs/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/motifs/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/motifs/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbilinear\u001b[0;34m(input1, input2, weight, bias)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/motifs/lib/python3.6/site-packages/torch/nn/_functions/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input1, input2, weight, bias)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# compute output scores:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mbuff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: matrices expected, got 1D, 2D tensors at /pytorch/torch/lib/TH/generic/THTensorMath.c:1429"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def manual_bilinear(x1, x2, A, b):\n",
    "    return torch.mm(x1, torch.mm(A, x2)) + b\n",
    "\n",
    "x_ones = torch.ones(2)\n",
    "x_zeros = torch.zeros(2)\n",
    "\n",
    "# ---------------------------\n",
    "# With Bias:\n",
    "\n",
    "B = nn.Bilinear(2, 2, 1)\n",
    "A = B.weight\n",
    "print(B.bias)\n",
    "# > tensor([-0.6748], requires_grad=True)\n",
    "b = B.bias\n",
    "\n",
    "print(B(x_ones, x_zeros))\n",
    "# > tensor([-0.6748], grad_fn=<ThAddBackward>)\n",
    "print(manual_bilinear(x_ones.view(1, 2), x_zeros.view(2, 1), A.squeeze(), b))\n",
    "# > tensor([[-0.6748]], grad_fn=<ThAddBackward>)\n",
    "\n",
    "print(B(x_ones, x_ones))\n",
    "# > tensor([-1.7684], grad_fn=<ThAddBackward>)\n",
    "print(manual_bilinear(x_ones.view(1, 2), x_ones.view(2, 1), A.squeeze(), b))\n",
    "# > tensor([[-1.7684]], grad_fn=<ThAddBackward>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 1D, 2D tensors at /pytorch/torch/lib/TH/generic/THTensorMath.c:1429",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c2d948495533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanual_bilinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_zeros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/motifs/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/motifs/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/motifs/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbilinear\u001b[0;34m(input1, input2, weight, bias)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbilinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/motifs/lib/python3.6/site-packages/torch/nn/_functions/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input1, input2, weight, bias)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# compute output scores:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mbuff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: matrices expected, got 1D, 2D tensors at /pytorch/torch/lib/TH/generic/THTensorMath.c:1429"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Without Bias:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def manual_bilinear(x1, x2, A, b):\n",
    "    return torch.mm(x1, torch.mm(A, x2)) + b\n",
    "\n",
    "x_ones = torch.ones(2)\n",
    "x_zeros = torch.zeros(2)\n",
    "print(x_ones)\n",
    "print(x_zeros)\n",
    "\n",
    "B = nn.Bilinear(2, 2, 1, bias=False)\n",
    "b = torch.zeros(1)\n",
    "\n",
    "print(B(x_ones, x_zeros))\n",
    "print(manual_bilinear(x_ones.view(1, 2), x_zeros.view(2, 1), A.squeeze(), b))\n",
    "\n",
    "print(B(x_ones, x_ones))\n",
    "print(manual_bilinear(x_ones.view(1, 2), x_ones.view(2, 1), A.squeeze(), b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ba81d3840abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/motifs/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/motifs/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/motifs/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbilinear\u001b[0;34m(input1, input2, weight, bias)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "m = nn.Bilinear(256, 256, 256)\n",
    "input1 = torch.randn(128, 256)\n",
    "input2 = torch.randn(128, 256)\n",
    "output = m(input1, input2)\n",
    "print(output.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
